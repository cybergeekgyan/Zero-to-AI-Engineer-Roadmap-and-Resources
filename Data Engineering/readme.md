## ðŸ”¥ Data Engineering & Big Data


## ðŸ‘€ Key Topics

- [Programming Languages](): Python, Java/Scala, SQL
- [Fundamentals of Data Engineering & Big Data]()
- [Big Data Ecosystem and Frameworks](): Hadoop(HDFS, MapReduce, YARN), Apache Spark, Hive, Pig, HBase, Kafka
- [Data Storage & Management](): Relational Databases(MySQL, PostgreSQL), NoSQL(MongoDB, Cassandra), Data Lakes, Data Warehouses(Snowflake, RedShift, BigQuery)
- [Data Ingestion & ETL/ELT](): ETL Tools(Apache Nifi, Talend, Informatica), Stream Processing(Apache Flink, Storm), Data Pipelines(Airflow, Luigi, Prefect)
- [Data Visualization](): Matplotlib, Seaborn, Plotly, Tableau, PowerBI, Superset
- [Cloud Platforms](): AWS, GCP, Azure
- [Distributed Systems](): Distributed Computing, Data Partitioning & Replication, Fault Tolerance & High Availability
- [File Formats for Big Data](): Avro, Parquet, ORC, JSON, CSV
- [Version Control](): Git, Github/Gitlab/GitBucket, DVC
- [Real-Time Data Processing](): Apache Kafka, Apache Flink, Apache Storm
- [Batch Processing](): Understanding of Hadoop & Spark, Optimizing techniques for large Batch Processing Jobs
- [Data Governance & Security](): Data Encryption, GDPR, HIPAA, Kerberos, Ranger, Knox
- [Data Quality, Catalog & Metadata Management](): Apache Griffin, DQM, Talend Data Quality, Informatica Data Quality, Apache Atlas, AWS Glue Data Catalog
- [CI/CD for Data Pipelines](): Jenkins, Github Actions, GitLab CI, Circle CI
- [Monitoring & Performance Optimization](): Prometheus, Grafana(for monitoring data pipelines), Spark UI, Ganglia, Nagios(monitoring performance in Hadoop/Spark ecosystems)
- [DevOps for Data Engineering](): Docker, Kubernetes
- [Machine Learning in Big Data](): Using Spark MLlib, Hadoop Mahout for large scale machine learning


## ðŸ§» Research Papers & Whitepapers

| Title                                                       | Authors                                      | Link                                                                  | Focus Areas                              |
| ------------------------------------------------------------ | -------------------------------------------- | --------------------------------------------------------------------- | ---------------------------------------- |
| MapReduce: Simplified Data Processing on Large Clusters      | Jeffrey Dean, Sanjay Ghemawat                | [Read Here](https://research.google.com/archive/mapreduce.html)        | Distributed computing, batch processing  |
| The Google File System                                       | Sanjay Ghemawat, Howard Gobioff, Shun-Tak Leung | [Read Here](https://research.google/pubs/archive/51.pdf)               | Distributed file systems, fault tolerance, data storage |
| Dynamo: Amazonâ€™s Highly Available Key-Value Store            | Giuseppe DeCandia et al.                     | [Read Here](https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf) | Distributed databases, consistency models, fault tolerance |
| Bigtable: A Distributed Storage System for Structured Data   | Fay Chang et al.                             | [Read Here](https://research.google.com/archive/bigtable.html)         | Distributed storage, NoSQL databases, scalability |
| Spanner: Googleâ€™s Globally-Distributed Database              | James C. Corbett et al.                      | [Read Here](https://research.google.com/archive/spanner.html)          | Distributed databases, global consistency, scalability |
| The CAP Theorem                                              | Eric Brewer                                  | [Read Here](https://dl.acm.org/doi/10.1145/3433850)                    | Distributed systems, trade-offs in distributed databases |
| Paxos Made Simple                                            | Leslie Lamport                               | [Read Here](https://lamport.azurewebsites.net/pubs/paxos-simple.pdf)   | Consensus algorithms, fault tolerance    |
| Spark: Cluster Computing with Working Sets                   | Matei Zaharia et al.                         | [Read Here](https://www.usenix.org/conference/hotcloud-10/spark-cluster-computing-working-sets) | Cluster computing, in-memory processing, large-scale data processing |
| The Data Lake: A Foundation for Big Data                     | James Dixon                                 | [Read Here](https://cdn2.hubspot.net/hubfs/2856332/Collateral/Whitepapers/Immuta_Whitepaper_What_is_a_Data_Lake.pdf) | Data lakes, storage systems, data governance |
| Tenzing: A SQL Implementation on the MapReduce Framework     | Tenzing Research Team                        | [Read Here](https://research.google/pubs/archive/37298.pdf)            | SQL-on-Hadoop, distributed SQL processing |

---

### Cutting-Edge and Advanced Whitepapers (2020s)

| Title                                                       | Authors                                      | Link                                                                  | Focus Areas                              |
| ------------------------------------------------------------ | -------------------------------------------- | --------------------------------------------------------------------- | ---------------------------------------- |
| Delta Lake: High-Performance ACID Table Storage over Cloud Object Stores | Michael Armbrust et al.                      | [Read Here](https://delta.io/wp-content/uploads/2020/06/Delta-Lake.pdf) | Data lakes, ACID transactions, cloud storage |
| DataOps: Delivering Data at Scale                            | Mark Lyons                                   | [Read Here](https://www.ibm.com/cloud/learn/dataops)                   | DataOps, automation, data quality        |
| Snowflake: The Data Warehouse Built for the Cloud            | Benoit Dageville et al.                      | [Read Here](https://www.snowflake.com/wp-content/uploads/2021/12/Snowflake-Architecture-Paper.pdf) | Cloud data warehousing, scalability, multi-cluster architecture |
| Beyond Lambda: Data Management in Real-Time Stream Processing Systems | Tyler Akidau et al.                          | [Read Here](https://dl.acm.org/doi/10.1145/2934664)                    | Stream processing, real-time systems, consistency |
| The Modern Data Stack: From Batch to Real-Time Analytics     | Various                                     | [Read Here](https://www.dbt.com/blog/the-modern-data-stack-whitepaper/) | Real-time analytics, cloud computing, modern data stack |

---

### Further Reading and Specialized Areas

| Title                                                       | Authors                                      | Link                                                                  | Focus Areas                              |
| ------------------------------------------------------------ | -------------------------------------------- | --------------------------------------------------------------------- | ---------------------------------------- |
| Lambda Architecture                                         | Nathan Marz                                  | [Read Here](https://lambda-architecture.net/)                          | Batch and stream processing architectures |
| Presto: SQL on Everything                                   | Martin Traverso et al.                       | [Read Here](https://prestodb.io/docs/current/overview/history.html)    | Distributed SQL engines, query optimization, scalability |

---


## ðŸ§° Tools & Technologies

- [Programming Languages](): Python(Numpy, Pandas), Java/Scala, SQL
- [Big Data Processing Frameworks](): Apache Hadoop(HDFS, MapReduce, YARN), Apache Spark(Spark Core, Spark SQL, Spark Streaming, Spark MLlib, PySpark)
- [Data Visualization Tools](): Tableau, PowerBI, Superset, Looker
- [Data Storage & Management Tools](): HDFS, NoSQL Databases(HBase, MongoDB, Cassandra), Relational Databases(MySQL, PostgreSQL), Data Lakes(AWS S3, Azure Data lake, Google Cloud Storage), Data Warehouses(Snowflake, Redshift, BigQuery)
- [Data Ingestion & ETL Tools](): Apache Nifi, Apache Flume, Talend, Informatica, Airbyte, Apache Sqoop
- [Real-Time Data Streaming Tools](): Apache Kafka, Apache Flink, Apache Storm, Kinesis(AWS), Kafka Streams
- [Workflow Orchestration Tools](): Airflow, Luigi, Prefect, Dagster
- [File Formats for Big Data](): Avro, Parquet, ORC, JSON, CSV
- [Cloud Platforms & Services](): AWS(EMR, S3, RedShift, Kinesis, Glue), Google Cloud(BigQuery, Dataproc, Dataflow), Azure(Azure Data Lake Storage, Azure Synapse Analytics, HDInsight, Azure Databricks)
- [Containers & Orchestration](): Docker & Kubernetes
- [Data Pipeline & Integration Tools](): Apache beam, DBT, Luigi, Airflow, Prefect
- [Monitoring & Logging Tools](): Prometheus, Grafana, ELK Stack, Spark UI
- [Data Security & Governance](): Apache Ranger, Apache Knox, Kerberos, Atlas
- [CI/CD Tools](): Jenkins, CircleCI, Travis CI, GitHub Actions
- [DevOps](): Terraform, Ansible, Puppet/Chef
- [Version Control](): Git, GitHub, GitLab, DVC
- [Machine learning and AI Integrations](): Spark MLlib, H20.ai, Tensorflow on Spark


## ðŸŸ¢ Projects

| Project Name | Description | Tools | Tags | Difficulty level | Link | Blog |
| --------|-------|-----|-------|-------|-----|-------|
| [Log File Analysis Using Apache Hadoop]() | Set up a Hadoop environment and process log files (like web server logs) to extract useful insights, such as visitor counts, error rates, and popular pages | `Hadoop`, `HDFS`, `MapReduce`, `Hive` | `Beginner` |
| [Data Ingestion Pipeline with Apache NiFi]() | Build a simple data ingestion pipeline to move data from a relational database (e.g., MySQL) to a data lake (e.g., HDFS) | `Apache NiFi`, `MySQL`, `HDFS` | `Beginner` |
| [Stream Processing with Apache Kafka]() | Create a simple producer-consumer model using Apache Kafka to stream data (like Twitter data) in real-time | `Python`, `Apache Kafka` | `Beginner` |
| [Data Warehouse ETL Pipeline]() | Build an ETL pipeline that extracts data from a source (e.g., a CSV file), transforms it (cleaning, aggregating), and loads it into a cloud-based data warehouse (e.g., Amazon Redshift or Snowflake) | `Python`, `AWS Redshift`, `Snowflake`, `Airflow`, `AWS S3` | `Intermediate` |
| [Batch Processing with Apache Spark and Parquet]() | Process a large dataset (e.g., sensor data or retail transactions) using Apache Spark and store the output in Parquet format for efficient querying | `Python`, `Apache Spark`, `Parquet`, `AWS S3`, `Google Cloud Storage` | `Intermediate` |
| [Real-Time Data Processing with Apache Spark Streaming]() | Build a real-time data processing application to process streaming data from Apache Kafka and store processed data into a NoSQL database (e.g., Cassandra or HBase) | `Python`, `Apache Spark Streaming`, `Kafka`, `Cassandra`, `HBase` | `Intermediate` |
| [Building a Data Lake on AWS S3]() | Build a data lake on AWS S3 where multiple raw datasets are stored, and then transform and process the data using tools like AWS Glue and Athena | `AWS S3`, `Glue`, `Athena`, `Python` | `Intermediate` |
| [Retail Sales Data Analysis with Spark and Hive]() | Analyze a large retail sales dataset to derive insights like sales trends, popular products, and customer demographics using Apache Spark for processing and Hive for querying | `Python`, `Apache Spark`, `Hive` | `Intermediate` |
| [Scalable Data Pipeline with Kubernetes and Apache Spark]() | Build a scalable data pipeline that runs Spark jobs on a Kubernetes cluster. Process large datasets and monitor resource usage and performance | `Kubernetes`, `Docker`, `Apache Spark`, `Helm` | `Advanced` |
| [Real-Time Recommendation System Using Kafka, Spark, and Cassandra]() | Build a real-time recommendation engine for a streaming platform (like Netflix) that suggests content based on user preferences and behavior | `Apache Kafka`, `Spark Streaming`, `Cassandra`, `Scala`, `PySpark` | `Advanced` |
| [Scalable Data Pipeline with Kubernetes and Apache Kafka]() | Build a scalable data pipeline that runs Spark jobs on a Kubernetes cluster. Process large datasets and monitor resource usage and performance | `Kubernetes`, `Docker`, `Apache Kafka`, `Helm` | `Advanced` |
| [Building a Scalable Data Warehouse on Snowflake]() | Set up a scalable data warehouse on Snowflake to analyze historical financial transactions. Build an efficient pipeline for daily data updates and advanced querying | `Snowflake`, `Python`, `SQL`, `dbt (Data Build Tool)`, `Airflow` | `Advanced` |
| [Distributed Stream Processing with Apache Flink]() | Implement a distributed stream processing system with Apache Flink to monitor and analyze real-time sensor data from IoT devices, with alerts on abnormal readings | `Apache Flink`, `Kafka`, `Cassandra`, `Grafana` | `Advanced` |
| [Building a Data Governance and Security Framework for Big Data]() | Build a data governance framework for a big data platform with Apache Ranger and Apache Atlas to ensure data security, auditing, and lineage tracking | `Apache Ranger`, `Atlas`, `Hadoop`, `Spark` | `Advanced` |
| [IoT Data Analytics Platform]() | Create a big data platform that collects and analyzes IoT sensor data, stores it in a distributed NoSQL database (e.g., MongoDB), and uses Spark for processing and analytics | `Apache Kafka`, `Spark`, `MongoDB`, `Grafana` | `Advanced` |
| [Optimizing Big Data Workflows with Spark and Airflow]() | Build an optimized data pipeline that handles complex workflows for a large e-commerce dataset using Apache Airflow to schedule and orchestrate Spark jobs | `Airflow`, `Spark`, `Parquet`, `S3` | `Advanced` |
| [Machine Learning at Scale with Apache Spark MLlib]() | Build a machine learning model (e.g., customer churn prediction) using Apache Spark MLlib on a large dataset. Train, validate, and deploy the model at scale | `Spark MLlib`, `HDFS`, `PySpark`, `S3` | `Advanced` |













