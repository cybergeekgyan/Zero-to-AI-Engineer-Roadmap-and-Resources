## üî• Roadmap to Become a LLM Engineer in 2024

1. Learn Python & NLP
2. Deep Learning Fundamentals
3. Understand Transformer Architecture
4. Fine-Tuning LLMs
5. Question Answering Models
6. Model Training & Optimization
7. RHLF
8. Multimodal Models
9. Efficient Model Deployment
10. Bias & Fairness in LLMs

## üìö Books

- [Transformers for Natural Language Processing]()
- [Deep Learning with PyTorch]()
- [NLP with Transformers]()
- [Grokking Transformers]()


## üìé Research Papers To Read

| Year | Paper | Keywords | Code | Blog |
| -----| ------|---------|-------|-----|
| 2017-06 | [Attention is All You Need](http://arxiv.org/pdf/1706.03762) | `Transformers` | 
| 2018-06 | [Improving Language Understanding by Generative Pre-Training](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf) | `GPT 1.0` |
| 2018-10 | [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://aclanthology.org/N19-1423.pdf) | `BERT` |
| 2020-05 | [Language Models are Few-Shot Learners](https://papers.nips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf) | `GPT 3.0` |




## Resources & Blogs 

- https://www.cs.princeton.edu/courses/archive/fa1122/cos597G/
- https://mlabonne.github.io/blog/https://youtu.be/kCc8FmEb1n√ù
- [Let's Build GPT](https://www.youtube.com/watch?v=kCc8FmEb1nY&pp=ygUObGV0cyBidWlsZCBncHQ%3D)
- https://jaykmody.com/blog/gpt-from-scratch/


## üß∞ LLMs Tools & Technologies















## LLM Projects










