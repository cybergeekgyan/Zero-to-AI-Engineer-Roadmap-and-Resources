## üî• Roadmap to Become a LLM Engineer in 2024

1. Learn Python & NLP
2. Deep Learning Fundamentals
3. Understand Transformer Architecture
4. Fine-Tuning LLMs
5. Question Answering Models
6. Model Training & Optimization
7. RHLF
8. Multimodal Models
9. Efficient Model Deployment
10. Bias & Fairness in LLMs

## üìö Books

- [Transformers for Natural Language Processing]()
- [Deep Learning with PyTorch]()
- [NLP with Transformers]()
- [Grokking Transformers]()


## üìé Research Papers To Read

| Year | Paper | Keywords | Code | Blog |
| -----| ------|---------|-------|-----|
| 2017-06 | [Attention is All You Need](http://arxiv.org/pdf/1706.03762) | `Transformers` | 
| 2018-06 | [Improving Language Understanding by Generative Pre-Training](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf) | `GPT 1.0` |
| 2018-10 | [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://aclanthology.org/N19-1423.pdf) | `BERT` |
| 2020-05 | [Language Models are Few-Shot Learners](https://papers.nips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf) | `GPT 3.0` |




## Resources & Blogs 

- https://www.cs.princeton.edu/courses/archive/fa1122/cos597G/
- https://mlabonne.github.io/blog/https://youtu.be/kCc8FmEb1n√ù
- [Let's Build GPT](https://www.youtube.com/watch?v=kCc8FmEb1nY&pp=ygUObGV0cyBidWlsZCBncHQ%3D)
- https://jaykmody.com/blog/gpt-from-scratch/
- [Creating a LLM from scratch with Python](https://youtu.be/UU1WVnMk4E8)
- https://stanford-cs324.github.io/winter2022/
- https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mamba-and-state?utm_source=multiple-personal-recommendations-email&utm_medium=email&open=false
- https://thegradient.pub
- https://distill.pub
- https://jalammar.github.io
- https://huggingface.co/blog
- [Cohere](https://cohere.com/llmu?_gl=1*1wvaezx*_ga*MTMxMjI2NTczOC4xNzI0MDcwOTM4*_ga_CRGS116RZS*MTcyNDA3MDkzNi4xLjEuMTcyNDA3MTAyNC40MC4wLjA.*_gcl_au*Nzg4ODI1MjUyLjE3MjQwNzA5Mzk)

## üß∞ LLMs Tools & Technologies

- [Programming Languages](): Python, Go/Java/Scala(For large-scale)
- [Libraries](): NumPy, Pandas, Matplotlib, Seaborn, Spacy, nltk
- [Data Processing Tools](): Pandas, Apache Spark, Polars
- [Deep Learning Frameworks](): PyTorch, TensorFlow, Keras
- [Model Training & Optimization Tools](): DeepSeed, TensorRT, Mixed Precision Training
- [Distributed Training Tools](): Horovod, Ray
- [Model Deployment Technologies](): ONNX, Triton, FastAPI, Docker, Kubernetes
- [Model Serving](): AWS SageMaker, HuggingFace Inference API
- [Evaluation & Testing Tools](): MLFlow, Kubeflow, W&B
- [Large-Scale Data Storage](): Google BigQuery, AWS RedShift
- [Datalake Technologies](): S3, Hadoop
- [Cloud Platforms](): AWS, GCP, Azure
- [Ethical AI & Bias Mitigation Tools](): IBM AI Fairness 360, Microsoft Fairlearn














## LLM Projects










