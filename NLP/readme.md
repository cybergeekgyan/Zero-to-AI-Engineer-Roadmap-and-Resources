# ðŸ”¥ NLP Concepts and Topics to Know

### [Foundations of NLP]()
- Introduction to NLP
- Linguistics Basics(Morphology, Syntax, Semantics, Pragmatics, 
- Text Processing
  -	Tokenization (word, sentence)
	-	Stop word removal
	-	Stemming and Lemmatization
	-	Text normalization (lowercasing, punctuation removal)
	-	N-grams and skip-grams
- Regular Expressions (Regex)
  -	Pattern matching
	-	Common use cases in text preprocessing
 
### [NLP Techniques]()

- Text Representation
  -	Bag of Words 
	-	Term Frequency-Inverse Document Frequency (TF-IDF)
	-	Word embeddings (Word2Vec, GloVe, FastText)
-	Sequence Models
  -	Markov Chains
	-	Hidden Markov Models (HMMs)
	-	Conditional Random Fields (CRFs)
- Text Classification
  -	Sentiment analysis
	-	Spam detection
	-	Topic modeling (LDA, NMF)
- Language Modeling
  -	Unigram, Bigram, and Trigram models
	-	Neural language models
	-	Pre-trained models (GPT, BERT, etc.)
- Named Entity Recognition (NER)
  -	Entity types (e.g., person, organization, location)
	-	Rule-based vs machine learning approaches
- Part-of-Speech (POS) Tagging
  -	Tagging techniques and algorithms
- Dependency Parsing
  -	Understanding syntactic structure and relationships
-	Word Sense Disambiguation
  -	Resolving ambiguity in word meanings
- Sentiment Analysis
  -	Rule-based vs machine learning-based approaches


### [Advanced NLP Concepts]()

- Deep Learning in NLP
  -	Recurrent Neural Networks (RNNs)
	-	Long Short-Term Memory (LSTM)
	-	Gated Recurrent Units (GRU)
	-	Attention Mechanisms
	-	Transformers (Self-Attention)
- Pre-trained Models and Transfer Learning
  -	BERT (Bidirectional Encoder Representations from Transformers)
	-	GPT (Generative Pre-trained Transformer)
	-	T5, XLNet, RoBERTa, ALBERT
	-	Sentence Transformers for embeddings (e.g., SBERT)
- Sequence-to-Sequence Models
  -	Machine Translation (e.g., seq2seq, attention)
	-	Summarization (extractive and abstractive)
-	Speech Processing (Optional)
  -	Automatic Speech Recognition (ASR)
	-	Text-to-Speech (TTS)
	-	Audio embeddings
- Conversational AI
  -	Chatbot frameworks (e.g., Rasa, Dialogflow)
	-	Retrieval-based vs Generative models
- NLP on Large Datasets
  -	Distributed training (Hugging Face Transformers, TensorFlow, PyTorch)
	-	Handling large corpora and data pipelines


## ðŸ“š NLP Books to Read

| Book Name | Link |
| --------|-------|
| [Natural Language Processing with Python - Steven Bird, Ewan Klein, and Edward Loper]() |
| [Speech and Language Processing]() |
| [Python Natural Language Processing - Jalaj Thanaki]() |
| [Deep Learning for Natural Language Processing]() | 
| [Natural Language Processing with Transformers]() |
| [Neural Network Methods in Natural Language Processing]() | 
| [Transformers for Natural Language Processing - Denis Rothman]() |


